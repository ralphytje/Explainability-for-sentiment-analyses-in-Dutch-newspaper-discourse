{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df14307",
   "metadata": {},
   "source": [
    "# Creating models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fd8967",
   "metadata": {},
   "source": [
    "# Lexicon models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d8cc1f",
   "metadata": {},
   "source": [
    "## Creating a pattern.nl lexicon model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "816c3cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  labels  \\\n",
      "0     DEN HAAG , 15 okt . Minister Andriessen ( Econ...       2   \n",
      "1     Om de kolen uit de mijnen bij de verbruiker te...       2   \n",
      "2     kolen willen de centrales niet. Olie is ten sl...       2   \n",
      "3     ( Van onze Haagse redactie ) i DEN HAAG , 15 n...       2   \n",
      "4     Dit en andere argumenten overwegend komt de st...       2   \n",
      "...                                                 ...     ...   \n",
      "1083  Aandeel olie en aardgas zal stijgen tot 33 en ...       1   \n",
      "1084  op Curacao zal nu een groter kwantum moeten ra...       0   \n",
      "1085  ESSEN , 21 okt . De Westduitse steenkolenmijne...       1   \n",
      "1086  ROTTERDAM , dinsdag De onderhandelingen die re...       2   \n",
      "1087  verwacht , dat de vraag naar olie verder- , za...       1   \n",
      "\n",
      "      predicted_sentiment  \n",
      "0                       0  \n",
      "1                       2  \n",
      "2                       2  \n",
      "3                       0  \n",
      "4                       0  \n",
      "...                   ...  \n",
      "1083                    2  \n",
      "1084                    2  \n",
      "1085                    0  \n",
      "1086                    2  \n",
      "1087                    0  \n",
      "\n",
      "[1088 rows x 3 columns]\n",
      "\n",
      "Classification Report for 1960s (Balanced):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.24      0.26      0.25       240\n",
      "     Neutral       0.51      0.30      0.37       443\n",
      "    Positive       0.50      0.63      0.56       656\n",
      "\n",
      "    accuracy                           0.45      1339\n",
      "   macro avg       0.42      0.39      0.39      1339\n",
      "weighted avg       0.46      0.45      0.44      1339\n",
      "\n",
      "\n",
      "Classification Report for 1970s (Balanced):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.41      0.19      0.26       510\n",
      "     Neutral       0.18      0.23      0.20       184\n",
      "    Positive       0.52      0.72      0.60       563\n",
      "\n",
      "    accuracy                           0.43      1257\n",
      "   macro avg       0.37      0.38      0.35      1257\n",
      "weighted avg       0.43      0.43      0.41      1257\n",
      "\n",
      "\n",
      "Classification Report for 1980s (Balanced):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.43      0.27      0.33       567\n",
      "     Neutral       0.25      0.29      0.27       307\n",
      "    Positive       0.45      0.55      0.50       783\n",
      "\n",
      "    accuracy                           0.40      1657\n",
      "   macro avg       0.38      0.37      0.37      1657\n",
      "weighted avg       0.41      0.40      0.40      1657\n",
      "\n",
      "\n",
      "Classification Report for 1990s (Balanced):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.59      0.22      0.31       567\n",
      "     Neutral       0.17      0.25      0.20       144\n",
      "    Positive       0.24      0.57      0.33       206\n",
      "\n",
      "    accuracy                           0.30       917\n",
      "   macro avg       0.33      0.35      0.28       917\n",
      "weighted avg       0.44      0.30      0.30       917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pattern.nl import sentiment\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Function to calculate sentiment score for each text\n",
    "def calculate_sentiment(text):\n",
    "    sentiment_tuple = sentiment(text)\n",
    "    polarity_score = sentiment_tuple[0]\n",
    "    if polarity_score < 0:\n",
    "        return 0  # Negative sentiment\n",
    "    elif polarity_score > 0:\n",
    "        return 2  # Positive sentiment\n",
    "    else:\n",
    "        return 1  # Neutral sentiment\n",
    "\n",
    "# Apply the sentiment calculation function to each row in the DataFrame\n",
    "df_1960s['predicted_sentiment'] = df_1960s['text'].apply(calculate_sentiment)\n",
    "df_1970s['predicted_sentiment'] = df_1970s['text'].apply(calculate_sentiment)\n",
    "df_1980s['predicted_sentiment'] = df_1980s['text'].apply(calculate_sentiment)\n",
    "df_1990s['predicted_sentiment'] = df_1990s['text'].apply(calculate_sentiment)\n",
    "\n",
    "print(df_1960s[['text', 'labels', 'predicted_sentiment']])\n",
    "\n",
    "# Function to balance classes by resampling\n",
    "def balance_classes(df):\n",
    "    # Separate majority and minority classes\n",
    "    df_negative = df[df['predicted_sentiment'] == 0]\n",
    "    df_neutral = df[df['predicted_sentiment'] == 1]\n",
    "    df_positive = df[df['predicted_sentiment'] == 2]\n",
    "\n",
    "    # Upsample minority class (neutral) to match majority class (negative)\n",
    "    df_neutral_upsampled = resample(df_neutral, replace=True, n_samples=len(df_negative), random_state=42)\n",
    "\n",
    "    # Combine majority class with upsampled minority class and majority class (positive)\n",
    "    df_balanced = pd.concat([df_negative, df_neutral_upsampled, df_positive])\n",
    "\n",
    "    return df_balanced\n",
    "\n",
    "# Balance classes for each decade\n",
    "df_1960s_balanced = balance_classes(df_1960s)\n",
    "df_1970s_balanced = balance_classes(df_1970s)\n",
    "df_1980s_balanced = balance_classes(df_1980s)\n",
    "df_1990s_balanced = balance_classes(df_1990s)\n",
    "\n",
    "# Generate classification reports for balanced datasets\n",
    "generate_classification_report(df_1960s_balanced, \"1960s (Balanced)\")\n",
    "generate_classification_report(df_1970s_balanced, \"1970s (Balanced)\")\n",
    "generate_classification_report(df_1980s_balanced, \"1980s (Balanced)\")\n",
    "generate_classification_report(df_1990s_balanced, \"1990s (Balanced)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe2e08c",
   "metadata": {},
   "source": [
    "# Machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff1cd85",
   "metadata": {},
   "source": [
    "## Creating logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "18b3153d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for df_1960s:\n",
      "Epoch 1, Loss: 14.412978708744049\n",
      "Epoch 2, Loss: 10.815499722957611\n",
      "Epoch 3, Loss: 8.943640410900116\n",
      "Epoch 4, Loss: 7.6798500418663025\n",
      "Epoch 5, Loss: 6.74244287610054\n",
      "Epoch 6, Loss: 6.0745609402656555\n",
      "Epoch 7, Loss: 5.565873354673386\n",
      "Epoch 8, Loss: 5.1498523354530334\n",
      "Epoch 9, Loss: 4.80529323220253\n",
      "Epoch 10, Loss: 4.440998762845993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.35      0.42        43\n",
      "           1       0.57      0.53      0.55        58\n",
      "           2       0.67      0.78      0.72       117\n",
      "\n",
      "    accuracy                           0.63       218\n",
      "   macro avg       0.59      0.55      0.57       218\n",
      "weighted avg       0.62      0.63      0.62       218\n",
      "\n",
      "Classification Report for df_1970s:\n",
      "Epoch 1, Loss: 12.724644601345062\n",
      "Epoch 2, Loss: 9.331070601940155\n",
      "Epoch 3, Loss: 8.013776659965515\n",
      "Epoch 4, Loss: 7.003912419080734\n",
      "Epoch 5, Loss: 6.363601893186569\n",
      "Epoch 6, Loss: 5.8573519587516785\n",
      "Epoch 7, Loss: 5.552736848592758\n",
      "Epoch 8, Loss: 5.301572382450104\n",
      "Epoch 9, Loss: 5.104619771242142\n",
      "Epoch 10, Loss: 4.942302495241165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.52      0.57        69\n",
      "           1       0.46      0.18      0.26        34\n",
      "           2       0.64      0.84      0.73       102\n",
      "\n",
      "    accuracy                           0.62       205\n",
      "   macro avg       0.58      0.51      0.52       205\n",
      "weighted avg       0.61      0.62      0.60       205\n",
      "\n",
      "\n",
      "Classification Report for df_1980s:\n",
      "Epoch 1, Loss: 16.786499679088593\n",
      "Epoch 2, Loss: 12.339868009090424\n",
      "Epoch 3, Loss: 10.311918318271637\n",
      "Epoch 4, Loss: 9.000965058803558\n",
      "Epoch 5, Loss: 8.056744754314423\n",
      "Epoch 6, Loss: 7.442700445652008\n",
      "Epoch 7, Loss: 6.986719489097595\n",
      "Epoch 8, Loss: 6.62293067574501\n",
      "Epoch 9, Loss: 6.303278177976608\n",
      "Epoch 10, Loss: 6.112340301275253\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.71      0.67       102\n",
      "           1       0.47      0.39      0.42        44\n",
      "           2       0.71      0.69      0.70       118\n",
      "\n",
      "    accuracy                           0.65       264\n",
      "   macro avg       0.61      0.60      0.60       264\n",
      "weighted avg       0.64      0.65      0.64       264\n",
      "\n",
      "\n",
      "Classification Report for df_1990s:\n",
      "Epoch 1, Loss: 9.461560368537903\n",
      "Epoch 2, Loss: 8.15215814113617\n",
      "Epoch 3, Loss: 6.703300297260284\n",
      "Epoch 4, Loss: 6.1311274766922\n",
      "Epoch 5, Loss: 5.499449700117111\n",
      "Epoch 6, Loss: 5.082052975893021\n",
      "Epoch 7, Loss: 4.8410965502262115\n",
      "Epoch 8, Loss: 4.491100966930389\n",
      "Epoch 9, Loss: 4.391586899757385\n",
      "Epoch 10, Loss: 4.166912734508514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83        96\n",
      "           1       0.57      0.43      0.49        28\n",
      "           2       0.41      0.41      0.41        27\n",
      "\n",
      "    accuracy                           0.70       151\n",
      "   macro avg       0.59      0.57      0.58       151\n",
      "weighted avg       0.69      0.70      0.69       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a function to train and evaluate the logistic regression model\n",
    "def train_and_evaluate_model(X_train, y_train, X_test, y_test):\n",
    "    # Vectorize the text data\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    # Encode the labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train_vec.toarray(), dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test_vec.toarray(), dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)\n",
    "\n",
    "    # Define the logistic regression model\n",
    "    class LogisticRegression(nn.Module):\n",
    "        def __init__(self, input_size, output_size):\n",
    "            super(LogisticRegression, self).__init__()\n",
    "            self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            out = self.linear(x)\n",
    "            return out\n",
    "\n",
    "    # Set hyperparameters\n",
    "    input_size = X_train_tensor.shape[1]\n",
    "    output_size = len(label_encoder.classes_)\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 10\n",
    "    batch_size = 64\n",
    "\n",
    "    # Initialize the model, criterion, and optimizer\n",
    "    model = LogisticRegression(input_size, output_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Create DataLoader\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        target_names = [str(label) for label in label_encoder.classes_]\n",
    "        print(classification_report(y_test_tensor, predicted, target_names=target_names))\n",
    "        \n",
    "# Train and evaluate the model for df_1960s\n",
    "X_train_1960s, X_test_1960s, y_train_1960s, y_test_1960s = train_test_split(df_1960s['text'], df_1960s['labels'], test_size=0.2, random_state=42)\n",
    "print(\"Classification Report for df_1960s:\")\n",
    "train_and_evaluate_model(X_train_1960s, y_train_1960s, X_test_1960s, y_test_1960s)\n",
    "\n",
    "# Train and evaluate the model for df_1970s\n",
    "X_train_1970s, X_test_1970s, y_train_1970s, y_test_1970s = train_test_split(df_1970s['text'], df_1970s['labels'], test_size=0.2, random_state=42)\n",
    "print(\"Classification Report for df_1970s:\")\n",
    "train_and_evaluate_model(X_train_1970s, y_train_1970s, X_test_1970s, y_test_1970s)\n",
    "\n",
    "# Train and evaluate the model for df_1980s\n",
    "X_train_1980s, X_test_1980s, y_train_1980s, y_test_1980s = train_test_split(df_1980s['text'], df_1980s['labels'], test_size=0.2, random_state=42)\n",
    "print(\"\\nClassification Report for df_1980s:\")\n",
    "train_and_evaluate_model(X_train_1980s, y_train_1980s, X_test_1980s, y_test_1980s)\n",
    "\n",
    "# Train and evaluate the model for df_1990s\n",
    "X_train_1990s, X_test_1990s, y_train_1990s, y_test_1990s = train_test_split(df_1990s['text'], df_1990s['labels'], test_size=0.2, random_state=42)\n",
    "print(\"\\nClassification Report for df_1990s:\")\n",
    "train_and_evaluate_model(X_train_1990s, y_train_1990s, X_test_1990s, y_test_1990s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f29c290",
   "metadata": {},
   "source": [
    "## Creating random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "cf66a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for df_1960s:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.21      0.30        43\n",
      "           1       0.64      0.40      0.49        58\n",
      "           2       0.60      0.85      0.70       117\n",
      "\n",
      "    accuracy                           0.60       218\n",
      "   macro avg       0.58      0.48      0.50       218\n",
      "weighted avg       0.59      0.60      0.57       218\n",
      "\n",
      "\n",
      "Classification Report for df_1970s:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.45      0.48        69\n",
      "           1       0.36      0.15      0.21        34\n",
      "           2       0.59      0.75      0.66       102\n",
      "\n",
      "    accuracy                           0.55       205\n",
      "   macro avg       0.49      0.45      0.45       205\n",
      "weighted avg       0.52      0.55      0.53       205\n",
      "\n",
      "\n",
      "Classification Report for df_1980s:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.69      0.64       102\n",
      "           1       0.54      0.32      0.40        44\n",
      "           2       0.68      0.69      0.68       118\n",
      "\n",
      "    accuracy                           0.62       264\n",
      "   macro avg       0.60      0.56      0.57       264\n",
      "weighted avg       0.62      0.62      0.62       264\n",
      "\n",
      "\n",
      "Classification Report for df_1990s:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84        96\n",
      "           1       0.60      0.43      0.50        28\n",
      "           2       0.46      0.44      0.45        27\n",
      "\n",
      "    accuracy                           0.72       151\n",
      "   macro avg       0.62      0.58      0.60       151\n",
      "weighted avg       0.70      0.72      0.71       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "df_1960s = pd.read_csv('1960s_merged.csv')\n",
    "df_1970s = pd.read_csv('1970s_merged.csv')\n",
    "df_1980s = pd.read_csv('1980s_merged.csv')\n",
    "df_1990s = pd.read_csv('1990s_merged.csv')\n",
    "\n",
    "# Define a function to train and evaluate the RandomForestClassifier\n",
    "def train_and_evaluate_rf_model(X_train, y_train, X_test, y_test):\n",
    "    # Vectorize the text data\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    # Initialize the Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    rf_model.fit(X_train_vec, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = rf_model.predict(X_test_vec)\n",
    "\n",
    "    # Print classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Define a function to train and evaluate the RandomForestClassifier for any dataset\n",
    "def train_and_evaluate_rf_model_generic(X, y):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Call the previous function to train and evaluate the model\n",
    "    train_and_evaluate_rf_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Train and evaluate the model for df_1960s\n",
    "print(\"Classification Report for df_1960s:\")\n",
    "train_and_evaluate_rf_model_generic(df_1960s['text'], df_1960s['labels'])\n",
    "\n",
    "# Train and evaluate the model for df_1970s\n",
    "print(\"\\nClassification Report for df_1970s:\")\n",
    "train_and_evaluate_rf_model_generic(df_1970s['text'], df_1970s['labels'])\n",
    "\n",
    "# Train and evaluate the model for df_1980s\n",
    "print(\"\\nClassification Report for df_1980s:\")\n",
    "train_and_evaluate_rf_model_generic(df_1980s['text'], df_1980s['labels'])\n",
    "\n",
    "# Train and evaluate the model for df_1990s\n",
    "print(\"\\nClassification Report for df_1990s:\")\n",
    "train_and_evaluate_rf_model_generic(df_1990s['text'], df_1990s['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3750829",
   "metadata": {},
   "source": [
    "## Creating a Bertje model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c90f39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model for 1960s:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\schol\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ffa04001a54ff8a80e25d6dc2bfab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/55 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.0353288813070818\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e52c6ac3e1477e89987801135ec2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/55 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.9263863130049272\n",
      "Average validation loss: 0.9673236097608294\n",
      "Training and evaluating model for 1970s:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\schol\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9272977bdd476283e8c61b846c187f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/52 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.9514348048430222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5cfb762aac425fbc7ac62de0d79fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/52 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.8171293420287279\n",
      "Average validation loss: 0.8979719831393316\n",
      "Training and evaluating model for 1980s:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\schol\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e581563b5f3e4b4496e2c42701fc3dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/66 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.0038481562426596\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2b0923eb18402b9b10fd1af99824fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/66 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.8331479601787798\n",
      "Average validation loss: 0.8821979831246769\n",
      "Training and evaluating model for 1990s:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\schol\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c2e1bdcb944c78a77601423855043c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/38 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.9090703270937267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef0f15e927f41ddab8c28b3459ab23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/38 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.773032585256978\n",
      "Average validation loss: 0.7887689232826233\n",
      "\n",
      "Classification Report for 1960s:\n",
      "              precision    recall  f1-score     support\n",
      "0              0.500000  0.116279  0.188679   43.000000\n",
      "1              0.421053  0.137931  0.207792   58.000000\n",
      "2              0.560847  0.905983  0.692810  117.000000\n",
      "accuracy       0.545872  0.545872  0.545872    0.545872\n",
      "macro avg      0.493966  0.386731  0.363094  218.000000\n",
      "weighted avg   0.511652  0.545872  0.464330  218.000000\n",
      "\n",
      "Classification Report for 1970s:\n",
      "              precision    recall  f1-score     support\n",
      "0              0.553846  0.521739  0.537313   69.000000\n",
      "1              0.000000  0.000000  0.000000   34.000000\n",
      "2              0.597122  0.813725  0.688797  102.000000\n",
      "accuracy       0.580488  0.580488  0.580488    0.580488\n",
      "macro avg      0.383656  0.445155  0.408703  205.000000\n",
      "weighted avg   0.483521  0.580488  0.523570  205.000000\n",
      "\n",
      "Classification Report for 1980s:\n",
      "              precision    recall  f1-score     support\n",
      "0              0.626506  0.509804  0.562162  102.000000\n",
      "1              1.000000  0.022727  0.044444   44.000000\n",
      "2              0.555556  0.847458  0.671141  118.000000\n",
      "accuracy       0.579545  0.579545  0.579545    0.579545\n",
      "macro avg      0.727354  0.459996  0.425916  264.000000\n",
      "weighted avg   0.657042  0.579545  0.524586  264.000000\n",
      "\n",
      "Classification Report for 1990s:\n",
      "              precision    recall  f1-score     support\n",
      "0              0.648649  1.000000  0.786885   96.000000\n",
      "1              1.000000  0.035714  0.068966   28.000000\n",
      "2              0.500000  0.037037  0.068966   27.000000\n",
      "accuracy       0.649007  0.649007  0.649007    0.649007\n",
      "macro avg      0.716216  0.357584  0.308272  151.000000\n",
      "weighted avg   0.687220  0.649007  0.525391  151.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df_1960s = pd.read_csv('1960s_merged.csv')\n",
    "df_1970s = pd.read_csv('1970s_merged.csv')\n",
    "df_1980s = pd.read_csv('1980s_merged.csv')\n",
    "df_1990s = pd.read_csv('1990s_merged.csv')\n",
    "\n",
    "# Function to train and evaluate the BERTje-based classification model\n",
    "def train_and_evaluate_bertje_model(train_texts, train_labels, val_texts, val_labels, num_labels):\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\")\n",
    "\n",
    "# Tokenize the texts\n",
    "    train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=128)\n",
    "    val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Create PyTorch datasets\n",
    "    train_dataset = TensorDataset(torch.tensor(train_encodings['input_ids']),\n",
    "                                  torch.tensor(train_encodings['attention_mask']),\n",
    "                                  torch.tensor(train_labels.tolist()))\n",
    "    val_dataset = TensorDataset(torch.tensor(val_encodings['input_ids']),\n",
    "                                torch.tensor(val_encodings['attention_mask']),\n",
    "                                torch.tensor(val_labels.tolist()))\n",
    "\n",
    "# Load the pre-trained BERTje model\n",
    "    model = BertForSequenceClassification.from_pretrained(\"GroNLP/bert-base-dutch-cased\", num_labels=num_labels)\n",
    "\n",
    "# Define training parameters with low computing cost\n",
    "    batch_size = 16\n",
    "    epochs = 2\n",
    "    learning_rate = 2e-5\n",
    "\n",
    "# Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=RandomSampler(train_dataset))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, sampler=SequentialSampler(val_dataset))\n",
    "\n",
    "# Define optimizer and scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "    total_steps = len(train_loader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Move model to GPU if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "# Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}', unit='batch'):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs = {'input_ids': batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels': batch[2]}\n",
    "            model.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        print(f\"Average training loss: {avg_train_loss}\")\n",
    "\n",
    "# Evaluation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs = {'input_ids': batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels': batch[2]}\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "            logits = outputs.logits\n",
    "            val_preds.extend(torch.argmax(logits, dim=1).cpu().tolist())\n",
    "            val_labels.extend(inputs['labels'].cpu().tolist())\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Average validation loss: {avg_val_loss}\")\n",
    "\n",
    "# Classification report\n",
    "    report = classification_report(val_labels, val_preds, output_dict=True)\n",
    "    return report\n",
    "\n",
    "# Split the datasets and train/evaluate the model for each decade\n",
    "reports = {}\n",
    "for decade, df in zip([\"1960s\", \"1970s\", \"1980s\", \"1990s\"], [df_1960s, df_1970s, df_1980s, df_1990s]):\n",
    "    print(f\"Training and evaluating model for {decade}:\")\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(df['text'], df['labels'], test_size=0.2, random_state=42)\n",
    "    num_labels = len(df['labels'].unique())\n",
    "    report = train_and_evaluate_bertje_model(train_texts, train_labels, val_texts, val_labels, num_labels)\n",
    "    reports[decade] = report\n",
    "\n",
    "# Print the classification reports\n",
    "for decade, report in reports.items():\n",
    "    print(f\"\\nClassification Report for {decade}:\")\n",
    "    print(pd.DataFrame(report).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8464061",
   "metadata": {},
   "source": [
    "## Creating support vector machine (SVM) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f628a30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for df_1960s:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.33      0.42        43\n",
      "           1       0.66      0.43      0.52        58\n",
      "           2       0.67      0.89      0.76       117\n",
      "\n",
      "    accuracy                           0.66       218\n",
      "   macro avg       0.64      0.55      0.57       218\n",
      "weighted avg       0.65      0.66      0.63       218\n",
      "\n",
      "\n",
      "Classification Report for df_1970s:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.59      0.62        69\n",
      "           1       0.33      0.03      0.05        34\n",
      "           2       0.64      0.87      0.74       102\n",
      "\n",
      "    accuracy                           0.64       205\n",
      "   macro avg       0.54      0.50      0.47       205\n",
      "weighted avg       0.59      0.64      0.59       205\n",
      "\n",
      "\n",
      "Classification Report for df_1980s:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.75      0.64       102\n",
      "           1       0.43      0.07      0.12        44\n",
      "           2       0.69      0.69      0.69       118\n",
      "\n",
      "    accuracy                           0.61       264\n",
      "   macro avg       0.56      0.51      0.48       264\n",
      "weighted avg       0.60      0.61      0.58       264\n",
      "\n",
      "\n",
      "Classification Report for df_1990s:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81        96\n",
      "           1       0.50      0.18      0.26        28\n",
      "           2       0.36      0.30      0.33        27\n",
      "\n",
      "    accuracy                           0.66       151\n",
      "   macro avg       0.53      0.46      0.47       151\n",
      "weighted avg       0.62      0.66      0.62       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define a function to train and evaluate the SVM classifier\n",
    "def train_and_evaluate_svm_model(X_train, y_train, X_test, y_test):\n",
    "    # Initialize the TfidfVectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "    # Transform the text data\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    # Initialize SVM classifier\n",
    "    svm_model = SVC(kernel='linear')\n",
    "\n",
    "    # Train the SVM model\n",
    "    svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    y_pred = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "    # Generate classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Define a function to train and evaluate the SVM classifier for any dataset\n",
    "def train_and_evaluate_svm_model_generic(X, y):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Call the previous function to train and evaluate the model\n",
    "    train_and_evaluate_svm_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Train and evaluate the model for df_1960s\n",
    "print(\"Classification Report for df_1960s:\")\n",
    "train_and_evaluate_svm_model_generic(df_1960s['text'], df_1960s['labels'])\n",
    "\n",
    "# Train and evaluate the model for df_1970s\n",
    "print(\"\\nClassification Report for df_1970s:\")\n",
    "train_and_evaluate_svm_model_generic(df_1970s['text'], df_1970s['labels'])\n",
    "\n",
    "# Train and evaluate the model for df_1980s\n",
    "print(\"\\nClassification Report for df_1980s:\")\n",
    "train_and_evaluate_svm_model_generic(df_1980s['text'], df_1980s['labels'])\n",
    "\n",
    "# Train and evaluate the model for df_1990s\n",
    "print(\"\\nClassification Report for df_1990s:\")\n",
    "train_and_evaluate_svm_model_generic(df_1990s['text'], df_1990s['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca523617",
   "metadata": {},
   "source": [
    "## Creating Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "b42bb3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for df_1960s:\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.72      0.53        43\n",
      "           1       0.53      0.57      0.55        58\n",
      "           2       0.80      0.56      0.66       117\n",
      "\n",
      "    accuracy                           0.60       218\n",
      "   macro avg       0.59      0.62      0.58       218\n",
      "weighted avg       0.66      0.60      0.61       218\n",
      "\n",
      "Classification Report for df_1970s:\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.59      0.57        69\n",
      "           1       0.21      0.26      0.24        34\n",
      "           2       0.68      0.58      0.62       102\n",
      "\n",
      "    accuracy                           0.53       205\n",
      "   macro avg       0.48      0.48      0.48       205\n",
      "weighted avg       0.55      0.53      0.54       205\n",
      "\n",
      "\n",
      "Classification Report for df_1980s:\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.64      0.61       102\n",
      "           1       0.33      0.55      0.41        44\n",
      "           2       0.73      0.51      0.60       118\n",
      "\n",
      "    accuracy                           0.56       264\n",
      "   macro avg       0.55      0.56      0.54       264\n",
      "weighted avg       0.61      0.56      0.57       264\n",
      "\n",
      "\n",
      "Classification Report for df_1990s:\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.76      0.85        96\n",
      "           1       0.52      0.57      0.54        28\n",
      "           2       0.42      0.70      0.53        27\n",
      "\n",
      "    accuracy                           0.72       151\n",
      "   macro avg       0.64      0.68      0.64       151\n",
      "weighted avg       0.79      0.72      0.74       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Define a function to train and evaluate the Multinomial Naive Bayes classifier\n",
    "def train_and_evaluate_nb_model(X_train, y_train, X_test, y_test):\n",
    "    # Initialize the TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "    # Vectorize the text data\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Apply SMOTE to handle class imbalance\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "    # Train the Naive Bayes model\n",
    "    naive_bayes_model = MultinomialNB()\n",
    "    naive_bayes_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    y_pred = naive_bayes_model.predict(X_test_vec)\n",
    "\n",
    "    # Generate the classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Print the classification report\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Define a function to train and evaluate the Multinomial Naive Bayes classifier for the dataset\n",
    "def train_and_evaluate_nb_model_generic(X, y):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Call the previous function to train and evaluate the model\n",
    "    train_and_evaluate_nb_model(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "# Train and evaluate the model for df_1960s\n",
    "print(\"Classification Report for df_1960s:\")\n",
    "train_and_evaluate_nb_model_generic(df_1960s['text'], df_1960s['labels'])\n",
    "\n",
    "# Train and evaluate the model for df_1970s\n",
    "print(\"Classification Report for df_1970s:\")\n",
    "train_and_evaluate_nb_model_generic(df_1970s['text'], df_1970s['labels'])\n",
    "\n",
    "# Train and evaluate the model for df_1980s\n",
    "print(\"\\nClassification Report for df_1980s:\")\n",
    "train_and_evaluate_nb_model_generic(df_1980s['text'], df_1980s['labels'])\n",
    "\n",
    "# Train and evaluate the model for df_1990s\n",
    "print(\"\\nClassification Report for df_1990s:\")\n",
    "train_and_evaluate_nb_model_generic(df_1990s['text'], df_1990s['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943110a4",
   "metadata": {},
   "source": [
    "# Deep learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde25530",
   "metadata": {},
   "source": [
    "## Creating Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "a33f7149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for df_1960s:\n",
      "Epoch 1/5, Loss: 1.7358075380325317\n",
      "Epoch 2/5, Loss: 1.291062593460083\n",
      "Epoch 3/5, Loss: 1.312917709350586\n",
      "Epoch 4/5, Loss: 1.3171759843826294\n",
      "Epoch 5/5, Loss: 1.2926428318023682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\schol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\schol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00        43\n",
      "     Neutral       0.75      0.10      0.18        58\n",
      "    Positive       0.55      0.98      0.70       117\n",
      "\n",
      "    accuracy                           0.56       218\n",
      "   macro avg       0.43      0.36      0.30       218\n",
      "weighted avg       0.49      0.56      0.43       218\n",
      "\n",
      "\n",
      "Classification Report for df_1970s:\n",
      "Epoch 1/5, Loss: 1.662696123123169\n",
      "Epoch 2/5, Loss: 1.3022541999816895\n",
      "Epoch 3/5, Loss: 1.2186795473098755\n",
      "Epoch 4/5, Loss: 1.2529387474060059\n",
      "Epoch 5/5, Loss: 1.202208399772644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\schol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\schol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.61      0.29      0.39        69\n",
      "     Neutral       0.00      0.00      0.00        34\n",
      "    Positive       0.55      0.93      0.69       102\n",
      "\n",
      "    accuracy                           0.56       205\n",
      "   macro avg       0.39      0.41      0.36       205\n",
      "weighted avg       0.48      0.56      0.48       205\n",
      "\n",
      "\n",
      "Classification Report for df_1980s:\n",
      "Epoch 1/5, Loss: 1.6154649257659912\n",
      "Epoch 2/5, Loss: 1.249168872833252\n",
      "Epoch 3/5, Loss: 1.3288295269012451\n",
      "Epoch 4/5, Loss: 1.2654683589935303\n",
      "Epoch 5/5, Loss: 1.153156042098999\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.55      0.58      0.56       102\n",
      "     Neutral       1.00      0.02      0.04        44\n",
      "    Positive       0.56      0.74      0.64       118\n",
      "\n",
      "    accuracy                           0.56       264\n",
      "   macro avg       0.70      0.45      0.41       264\n",
      "weighted avg       0.63      0.56      0.51       264\n",
      "\n",
      "\n",
      "Classification Report for df_1990s:\n",
      "Epoch 1/5, Loss: 1.5509506464004517\n",
      "Epoch 2/5, Loss: 1.238114595413208\n",
      "Epoch 3/5, Loss: 1.116990566253662\n",
      "Epoch 4/5, Loss: 0.9925248622894287\n",
      "Epoch 5/5, Loss: 0.912257969379425\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.94      0.82        96\n",
      "     Neutral       0.36      0.32      0.34        28\n",
      "    Positive       0.33      0.04      0.07        27\n",
      "\n",
      "    accuracy                           0.66       151\n",
      "   macro avg       0.48      0.43      0.41       151\n",
      "weighted avg       0.59      0.66      0.60       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "df_1960s = pd.read_csv('1960s_merged.csv')\n",
    "df_1970s = pd.read_csv('1970s_merged.csv')\n",
    "df_1980s = pd.read_csv('1980s_merged.csv')\n",
    "df_1990s = pd.read_csv('1990s_merged.csv')\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_seq_length = 512\n",
    "\n",
    "# Function to tokenize text\n",
    "def tokenize_text(text):\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=max_seq_length)\n",
    "    return tokens[:max_seq_length] + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_filters, filter_sizes, output_dim, dropout):\n",
    "        super(CNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(fs, embedding_dim))\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        self.fc = nn.Linear(len(filter_sizes) * num_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # [batch_size, seq_len, emb_dim]\n",
    "        x = x.unsqueeze(1)  # [batch_size, 1, seq_len, emb_dim]\n",
    "        conved = [F.relu(conv(x)).squeeze(3) for conv in self.convs]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "        return self.fc(cat)\n",
    "\n",
    "# Hyperparameters\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embedding_dim = 128\n",
    "num_filters = 100\n",
    "filter_sizes = [3, 4, 5]\n",
    "output_dim = 3\n",
    "dropout = 0.5\n",
    "num_epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function to preprocess data and train the model\n",
    "def train_and_evaluate_cnn_model(df):\n",
    "    # Split the dataset into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['text'], df['labels'], test_size=0.2, random_state=42)\n",
    "\n",
    "    # Tokenize the text data\n",
    "    X_train_tokens = [tokenize_text(text) for text in X_train]\n",
    "    X_test_tokens = [tokenize_text(text) for text in X_test]\n",
    "\n",
    "    # Convert token lists to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train_tokens, dtype=torch.long).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test_tokens, dtype=torch.long).to(device)\n",
    "\n",
    "    # Convert y_train and y_test to tensors\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.long).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.long).to(device)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = CNN(vocab_size, embedding_dim, num_filters, filter_sizes, output_dim, dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        classification_rep = classification_report(y_test_tensor.cpu().numpy(), predicted.cpu().numpy(), target_names=['Negative', 'Neutral', 'Positive'])\n",
    "        print(\"Classification Report:\\n\", classification_rep)\n",
    "\n",
    "# Train and evaluate the model for each dataset\n",
    "print(\"Classification Report for df_1960s:\")\n",
    "train_and_evaluate_cnn_model(df_1960s)\n",
    "\n",
    "print(\"\\nClassification Report for df_1970s:\")\n",
    "train_and_evaluate_cnn_model(df_1970s)\n",
    "\n",
    "print(\"\\nClassification Report for df_1980s:\")\n",
    "train_and_evaluate_cnn_model(df_1980s)\n",
    "\n",
    "print(\"\\nClassification Report for df_1990s:\")\n",
    "train_and_evaluate_cnn_model(df_1990s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
